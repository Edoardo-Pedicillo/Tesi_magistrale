OMP: Info #270: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.
[Qibo 0.1.7|INFO|2022-06-02 16:05:06]: Using qibojit (numba) backend on /CPU:0
[Qibo 0.1.7|INFO|2022-06-02 16:05:15]: Using tensorflow backend on /device:CPU:0
[Qibo 0.1.7|WARNING|2022-06-02 16:05:15]: `set_threads` is not supported by the tensorflow backend. Please use tensorflow's thread setters: `tf.config.threading.set_inter_op_parallelism_threads` or `tf.config.threading.set_intra_op_parallelism_threads` to switch the number of threads.
Traceback (most recent call last):
  File "/home/edoardopedicillo/tesi/gamma_logistic/iterator/quantum_classical_1Dgamma.py", line 257, in <module>
    main(**args)
  File "/home/edoardopedicillo/tesi/gamma_logistic/iterator/quantum_classical_1Dgamma.py", line 243, in main
    train(discriminator, latent_dim, layers, nqubits, training_samples, discriminator, circuit, n_epochs, batch_samples, lr, hamiltonian1,nparams, iterator)
  File "/home/edoardopedicillo/tesi/gamma_logistic/iterator/quantum_classical_1Dgamma.py", line 190, in train
    optimizer.apply_gradients([(grads, initial_params)])
  File "/home/edoardopedicillo/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py", line 598, in apply_gradients
    grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)
  File "/home/edoardopedicillo/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/utils.py", line 79, in filter_empty_gradients
    ([v.name for _, v in grads_and_vars],))
ValueError: No gradients provided for any variable: ['Variable:0'].
srun: error: wick: task 0: Exited with exit code 1
